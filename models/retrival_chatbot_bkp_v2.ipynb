{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yp3kv9fOB__"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKNOX-jyOCAC",
    "outputId": "02e87292-bfb1-48a3-bec7-40bfe1fd97da"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUzhdj3kOCAE"
   },
   "source": [
    "### Import json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TF1Codf8OCAE"
   },
   "outputs": [],
   "source": [
    "with open('../data/firstaid.json') as f:\n",
    "    intents = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdYrfJEAOCAE"
   },
   "source": [
    "### Preprocessing data\n",
    "In this part we gonna clean data, split them into inputs and targets tensor, build a tokenizer dictionary and turn sentences into sequences.\n",
    "The target tensor has a bunch of list with a length of unique title list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "omGHG5rNOCAF"
   },
   "outputs": [],
   "source": [
    "def preprocessing(line):\n",
    "    line = re.sub(r'[^a-zA-z.?!\\']', ' ', line)\n",
    "    line = re.sub(r'[ ]+', ' ', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ilooSi7IOCAF"
   },
   "outputs": [],
   "source": [
    "# get text and intent title from json data\n",
    "inputs, targets = [], []\n",
    "classes = []\n",
    "intent_doc = {}\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    if intent['intent'] not in classes:\n",
    "        classes.append(intent['intent'])\n",
    "    if intent['intent'] not in intent_doc:\n",
    "        intent_doc[intent['intent']] = []\n",
    "        \n",
    "    for text in intent['text']:\n",
    "        inputs.append(preprocessing(text))\n",
    "        targets.append(intent['intent'])\n",
    "        \n",
    "    for response in intent['responses']:\n",
    "        intent_doc[intent['intent']].append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "axOCvNdcOCAF"
   },
   "outputs": [],
   "source": [
    "def tokenize_data(input_list):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<unk>')\n",
    "    \n",
    "    tokenizer.fit_on_texts(input_list)\n",
    "    \n",
    "    input_seq = tokenizer.texts_to_sequences(input_list)\n",
    "\n",
    "    input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, padding='pre')\n",
    "    \n",
    "    return tokenizer, input_seq\n",
    "\n",
    "# preprocess input data\n",
    "tokenizer, input_tensor = tokenize_data(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "C3-d3j_1OCAG"
   },
   "outputs": [],
   "source": [
    "def create_categorical_target(targets):\n",
    "    word={}\n",
    "    categorical_target=[]\n",
    "    counter=0\n",
    "    for trg in targets:\n",
    "        if trg not in word:\n",
    "            word[trg]=counter\n",
    "            counter+=1\n",
    "        categorical_target.append(word[trg])\n",
    "    \n",
    "    categorical_tensor = tf.keras.utils.to_categorical(categorical_target, num_classes=len(word), dtype='int32')\n",
    "    return categorical_tensor, dict((v,k) for k, v in word.items())\n",
    "\n",
    "# preprocess output data\n",
    "target_tensor, trg_index_word = create_categorical_target(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FsEdGRG1OCAG",
    "outputId": "32cd2989-01b4-4c84-8bb5-ec14c5a4863b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (188, 11) and output shape: (188, 44)\n"
     ]
    }
   ],
   "source": [
    "print('input shape: {} and output shape: {}'.format(input_tensor.shape, target_tensor.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gih8EUv8OCAH"
   },
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "EUOiHAHNOCAH"
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "epochs=50\n",
    "vocab_size=len(tokenizer.word_index) + 1\n",
    "embed_dim=512\n",
    "units=128\n",
    "target_length=target_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQuRrEV8OCAI",
    "outputId": "ea5e2a79-dbd7-44a2-8c28-095078e35532"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 512)         78848     \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 256)              656384    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 44)                5676      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 773,804\n",
      "Trainable params: 773,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build RNN Model with tensorflow\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embed_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units, dropout=0.2)),\n",
    "    tf.keras.layers.Dense(units, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(target_length, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=1e-2)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pR_slxDdOCAI",
    "outputId": "88dcfcf9-aed3-4608-b5f0-7cf2d8a9c9a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 5s 26ms/step - loss: 3.7803 - accuracy: 0.0160\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.7632 - accuracy: 0.0426\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.7473 - accuracy: 0.0532\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.6972 - accuracy: 0.1117\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.6546 - accuracy: 0.1277\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 3.5700 - accuracy: 0.1702\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 3.4697 - accuracy: 0.1968\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 3.3894 - accuracy: 0.2021\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 3.1122 - accuracy: 0.2128\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.8751 - accuracy: 0.2979\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.4594 - accuracy: 0.3670\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.1338 - accuracy: 0.4734\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.8436 - accuracy: 0.5372\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.4554 - accuracy: 0.6383\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1829 - accuracy: 0.7500\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8849 - accuracy: 0.8298\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.7549 - accuracy: 0.8670\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.6447 - accuracy: 0.8564\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.5446 - accuracy: 0.8883\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.3860 - accuracy: 0.9521\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3697 - accuracy: 0.9415\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.2686 - accuracy: 0.9681\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2531 - accuracy: 0.9734\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.1884 - accuracy: 0.9787\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1827 - accuracy: 0.9681\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1772 - accuracy: 0.9681\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.1316 - accuracy: 0.9840\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.1523 - accuracy: 0.9681\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0963 - accuracy: 0.9947\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0931 - accuracy: 0.9894\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0935 - accuracy: 0.9894\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0897 - accuracy: 0.9947\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0556 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0540 - accuracy: 0.9947\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0514 - accuracy: 0.9947\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0546 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0445 - accuracy: 0.9947\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0521 - accuracy: 0.9947\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.0497 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.0449 - accuracy: 0.9947\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.0360 - accuracy: 0.9947\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0435 - accuracy: 0.9947\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0470 - accuracy: 0.9947\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0416 - accuracy: 0.9947\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.0328 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 0.0314 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0410 - accuracy: 0.9947\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0363 - accuracy: 0.9947\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0274 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.0334 - accuracy: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x138e80c10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4)\n",
    "\n",
    "# train the model\n",
    "model.fit(input_tensor, target_tensor, epochs=epochs, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "SxEugGEKOCAI",
    "outputId": "ee7efc92-e1a5-4eac-89c6-a89c5ad9c6a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Enter 'quit' to break the loop.\n",
      "You: help me with feter\n",
      "Bot: 1)Place your ear next to the person's mouth and nose. Do you feel air on your cheek? 2)Look to see if the person's chest is moving.If the Person is Not Breathing, Check Pulse. 3)Check the person's pulse for 10 seconds.If There is No Pulse, Start CPR. -- TYPE: Drowning\n",
      "\n",
      "You: help me with cough\n",
      "Bot: 1)Place your ear next to the person's mouth and nose. Do you feel air on your cheek? 2)Look to see if the person's chest is moving.If the Person is Not Breathing, Check Pulse. 3)Check the person's pulse for 10 seconds.If There is No Pulse, Start CPR. -- TYPE: Drowning\n",
      "\n",
      "You: cure for cough\n",
      "Bot:   -- TYPE: Eye Injury\n",
      "\n",
      "You: snake bite\n",
      "Bot: While waiting for medical help: 1)Move the person beyond striking distance of the snake. 2)Have the person lie down with wound below the heart. 3)Keep the person calm and at rest, remaining as still as possible to keep venom from spreading. 4)Cover the wound with loose, sterile bandage. 5)Remove any jewelry from the area that was bitten. 6)Remove shoes if the leg or foot was bitten. -- TYPE: snake bite\n",
      "\n",
      "You: cough\n",
      "Bot: 1) Honey:- Use honey to treat a cough, mix 2 teaspoons (tsp) with warm water or an herbal tea. Drink this mixture once or twice a day. Do not give honey to children under 1 year of age. 2) Ginger:- Brew up a soothing ginger tea by adding 20â€“40 grams (g) of fresh ginger slices to a cup of hot water. Allow to steep for a few minutes before drinking. Add honey or lemon juice to improve the taste and further soothe a cough. 3) Fluids:- Staying hydrated is vital for those with a cough or cold. Research indicates that drinking liquids at room temperature can alleviate a cough, runny nose, and sneezing. -- TYPE: Cough\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def response(sentence):\n",
    "    sent_seq = []\n",
    "    doc = nlp(repr(sentence))\n",
    "    \n",
    "    # split the input sentences into words\n",
    "    for token in doc:\n",
    "        if token.text in tokenizer.word_index:\n",
    "            sent_seq.append(tokenizer.word_index[token.text])\n",
    "\n",
    "        # handle the unknown words error\n",
    "        else:\n",
    "            sent_seq.append(tokenizer.word_index['<unk>'])\n",
    "\n",
    "    sent_seq = tf.expand_dims(sent_seq, 0)\n",
    "    # predict the category of input sentences\n",
    "    pred = model(sent_seq)\n",
    "\n",
    "    pred_class = np.argmax(pred.numpy(), axis=1)\n",
    "    \n",
    "    # choice a random response for predicted sentence\n",
    "    return random.choice(intent_doc[trg_index_word[pred_class[0]]]), trg_index_word[pred_class[0]]\n",
    "\n",
    "# chat with bot\n",
    "print(\"Note: Enter 'quit' to break the loop.\")\n",
    "while True:\n",
    "    input_ = input('You: ')\n",
    "    if input_.lower() == 'quit':\n",
    "        break\n",
    "    res, typ = response(input_)\n",
    "    print('Bot: {} -- TYPE: {}'.format(res, typ))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsHZ1BsaOCAI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
